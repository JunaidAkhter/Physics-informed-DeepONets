{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPELV+tSLmSsq3wC0lubJGu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunaidAkhter/Physics-informed-DeepONets/blob/main/CopyofPytorchAntider.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Pytorch` implementation of Physics informed DeepOnet to solve\n",
        "$$\n",
        "\\frac{ds(x)}{dx} = u(x), \\hspace{1cm} x ∈[0, 1]\n",
        "$$\n",
        "**Literature:**\n",
        "\n",
        "\n",
        "1.   [DeepOnets](https://arxiv.org/pdf/1910.03193.pdf)\n",
        "2.   [Physics Informed DeepONets](https://arxiv.org/pdf/2103.10974.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "tiLrS670EGM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ulYqHZCP6Hxz"
      },
      "outputs": [],
      "source": [
        "#@title importing modules\n",
        "import numpy as onp\n",
        "import jax.numpy as np\n",
        "from jax import random, grad, vmap, jit\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.experimental.ode import odeint\n",
        "from jax.nn import relu\n",
        "from jax.config import config\n",
        "import itertools\n",
        "from functools import partial\n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let us generate the data first.\n",
        "We use RBF to generate the training and the testing data. \\\\\n",
        "**Note:** The data is being generated using `Jax`. However, we use Pytorch for learning. Hence we convert the generated data to numpy arrays which is later on converted to `torch` tensors."
      ],
      "metadata": {
        "id": "fUKGNYq9CXec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title RBF and data generation.\n",
        "# Length scale of a Gaussian random field (GRF)\n",
        "length_scale = 0.2\n",
        "\n",
        "# Define RBF kernel\n",
        "def RBF(x1, x2, params):\n",
        "    output_scale, lengthscales = params\n",
        "    diffs = np.expand_dims(x1 / lengthscales, 1) - \\\n",
        "            np.expand_dims(x2 / lengthscales, 0)\n",
        "    r2 = np.sum(diffs**2, axis=2)\n",
        "    return output_scale * np.exp(-0.5 * r2)\n",
        "\n",
        "# Geneate training data corresponding to one input sample\n",
        "def generate_one_training_data(key, m=100, P=1):\n",
        "    # Sample GP prior at a fine grid\n",
        "    N = 512\n",
        "    gp_params = (1.0, length_scale)\n",
        "    jitter = 1e-10\n",
        "    X = np.linspace(0, 1, N)[:,None]\n",
        "    K = RBF(X, X, gp_params)\n",
        "    L = np.linalg.cholesky(K + jitter*np.eye(N))\n",
        "    gp_sample = np.dot(L, random.normal(key, (N,)))\n",
        "\n",
        "    # Create a callable interpolation function\n",
        "    u_fn = lambda x, t: np.interp(t, X.flatten(), gp_sample)\n",
        "\n",
        "    # Input sensor locations and measurements\n",
        "    x = np.linspace(0, 1, m)\n",
        "    u = vmap(u_fn, in_axes=(None,0))(0.0, x)\n",
        "\n",
        "    # Output sensor locations and measurements\n",
        "    y_train = random.uniform(key, (P,)).sort()\n",
        "    s_train = odeint(u_fn, 0.0, np.hstack((0.0, y_train)))[1:] # JAX has a bug and always returns s(0), so add a dummy entry to y and return s[1:]\n",
        "\n",
        "    # Tile inputs\n",
        "    u_train = np.tile(u, (P,1))\n",
        "\n",
        "    # training data for the residual\n",
        "    u_r_train = np.tile(u, (m, 1))  # CREATES m COPIES of u.\n",
        "    y_r_train = x\n",
        "    s_r_train = u    # STUPID NAMING WALLAHI\n",
        "\n",
        "    #print(\"shape of u_r_train:\", u_r_train.shape)\n",
        "    #print(\"shape of s_r_train:\", s_r_train.shape)\n",
        "\n",
        "    return u_train, y_train, s_train, u_r_train, y_r_train,  s_r_train\n",
        "\n",
        "# Geneate test data corresponding to one input sample\n",
        "def generate_one_test_data(key, m=100, P=100):\n",
        "    # Sample GP prior at a fine grid\n",
        "    N = 512\n",
        "    gp_params = (1.0, length_scale)\n",
        "    jitter = 1e-10\n",
        "    X = np.linspace(0, 1, N)[:,None]\n",
        "    K = RBF(X, X, gp_params)\n",
        "    L = np.linalg.cholesky(K + jitter*np.eye(N))\n",
        "    gp_sample = np.dot(L, random.normal(key, (N,)))\n",
        "\n",
        "    # Create a callable interpolation function\n",
        "    u_fn = lambda x, t: np.interp(t, X.flatten(), gp_sample)\n",
        "\n",
        "    # Input sensor locations and measurements\n",
        "    x = np.linspace(0, 1, m)\n",
        "    u = vmap(u_fn, in_axes=(None,0))(0.0, x)\n",
        "\n",
        "    # Output sensor locations and measurements\n",
        "    y = np.linspace(0, 1, P)\n",
        "    s = odeint(u_fn, 0.0, y)\n",
        "\n",
        "    # Tile inputs\n",
        "    u = np.tile(u, (P,1))\n",
        "\n",
        "    return u, y, s\n",
        "\n",
        "# Geneate training data corresponding to N input sample\n",
        "def generate_training_data(key, N, m, P):\n",
        "    config.update(\"jax_enable_x64\", True)\n",
        "    keys = random.split(key, N)\n",
        "    gen_fn = jit(lambda key: generate_one_training_data(key, m, P))\n",
        "    u_train, y_train, s_train, u_r_train, y_r_train, s_r_train = vmap(gen_fn)(keys)\n",
        "\n",
        "    u_train = np.float32(u_train.reshape(N * P,-1))\n",
        "    y_train = np.float32(y_train.reshape(N * P,-1))\n",
        "    s_train = np.float32(s_train.reshape(N * P,-1))\n",
        "\n",
        "    u_r_train = np.float32(u_r_train.reshape(N * m,-1))\n",
        "    y_r_train = np.float32(y_r_train.reshape(N * m,-1))\n",
        "    s_r_train = np.float32(s_r_train.reshape(N * m,-1))\n",
        "\n",
        "    config.update(\"jax_enable_x64\", False)\n",
        "    return u_train, y_train, s_train, u_r_train, y_r_train,  s_r_train\n",
        "\n",
        "# Geneate test data corresponding to N input sample\n",
        "def generate_test_data(key, N, m, P):\n",
        "    config.update(\"jax_enable_x64\", True)\n",
        "    keys = random.split(key, N)\n",
        "    gen_fn = jit(lambda key: generate_one_test_data(key, m, P))\n",
        "    u, y, s = vmap(gen_fn)(keys)\n",
        "    u = np.float32(u.reshape(N * P,-1))\n",
        "    y = np.float32(y.reshape(N * P,-1))\n",
        "    s = np.float32(s.reshape(N * P,-1))\n",
        "\n",
        "    config.update(\"jax_enable_x64\", False)\n",
        "    return u, y, s"
      ],
      "metadata": {
        "id": "nUUN_m8l6QsS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generating training data and converting jax.numpy to onp\n",
        "N_train = 10000 # number of input samples\n",
        "m = 100 # number of input sensors\n",
        "P_train = 1   # number of output sensors\n",
        "key_train = random.PRNGKey(0) # use different key for generating training data and test data\n",
        "u_train, y_train, s_train, u_r_train, y_r_train, s_r_train = generate_training_data(key_train, N_train, m, P_train)\n",
        "\n",
        "#changing to numpy\n",
        "#u_train, y_train, s_train, u_r_train, y_r_train, s_r_train = onp.array(u_train), onp.array(y_train), onp.array(s_train), onp.array(u_r_train), onp.array(y_r_train), onp.array(s_r_train)\n",
        "\n",
        "#print(\"type of data that we have now:\", type(u_train), type(y_train), type(s_train), type(u_r_train), type(y_r_train), type(s_r_train))\n",
        "\n"
      ],
      "metadata": {
        "id": "E4T4CD8O6ZQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16d2784-0768-4081-d1af-3c33c8f78b4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(u_train), u_train.shape)\n",
        "print(len(u_r_train), u_r_train.shape)\n",
        "print(type(u_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5S265m1IJbH",
        "outputId": "b75c9a87-154a-44b2-83ec-8617f58c39b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 (10000, 100)\n",
            "1000000 (1000000, 100)\n",
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generating test data\n",
        "N_test = 100\n",
        "P_test = m\n",
        "key_test = random.PRNGKey(12345)\n",
        "keys_test = random.split(key_test, N_test)\n",
        "\n",
        "u_test, y_test, s_test =  generate_test_data(key_test, N_test, m, m)\n",
        "\n",
        "#u_test, y_test, s_test = onp.array(u_test), onp.array(y_test), onp.array(s_test)\n",
        "print(type(u_test), type(y_test), type(s_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI5ztq7hB7J7",
        "outputId": "66a9df68-8499-4344-8a0a-7ea64547fc06"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'jaxlib.xla_extension.ArrayImpl'> <class 'jaxlib.xla_extension.ArrayImpl'> <class 'jaxlib.xla_extension.ArrayImpl'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generator\n",
        "class DataGenerator(data.Dataset):\n",
        "    def __init__(self, u, y, s,\n",
        "                 batch_size=64, rng_key=random.PRNGKey(1234)):\n",
        "        'Initialization'\n",
        "        self.u = u # input sample\n",
        "        self.y = y # location\n",
        "        self.s = s # labeled data evulated at y (solution measurements, BC/IC conditions, etc.)\n",
        "\n",
        "        self.N = u.shape[0]\n",
        "        self.batch_size = batch_size\n",
        "        self.key = rng_key\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        self.key, subkey = random.split(self.key)\n",
        "        inputs, outputs = self.__data_generation(subkey)\n",
        "        return inputs, outputs\n",
        "\n",
        "    @partial(jit, static_argnums=(0,))\n",
        "    def __data_generation(self, key):\n",
        "        'Generates data containing batch_size samples'\n",
        "        idx = random.choice(key, self.N, (self.batch_size,), replace=False)\n",
        "        s = self.s[idx,:]\n",
        "        y = self.y[idx,:]\n",
        "        u = self.u[idx,:]\n",
        "        # Construct batch\n",
        "        inputs = (u, y)\n",
        "        outputs = s\n",
        "        return inputs, outputs"
      ],
      "metadata": {
        "id": "8ObP0I87GmJ-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solving the Problem\n",
        "Now that we have the data (as numpy arrays which can easily be converted to torch tensors), we would like to use this to learn the operator $G$ as discussed in the paper [Physics Informed DeepONets](https://arxiv.org/pdf/2103.10974.pdf).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I01vP3GjFRF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import grad\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import itertools\n",
        "from functools import partial\n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from typing import Callable\n"
      ],
      "metadata": {
        "id": "WJOQZ7O66gTM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data set\n",
        "batch_size = 10000   #TODO: bigger batches do not work for some reasons.\n",
        "operator_dataset = DataGenerator(u_train, y_train, s_train, batch_size)\n",
        "physics_dataset = DataGenerator(u_r_train, y_r_train, s_r_train, batch_size)"
      ],
      "metadata": {
        "id": "IZXSqXTg78DF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checking how the batch data looks like\n",
        "max_epochs = 200\n",
        "\n",
        "operator_data = iter(operator_dataset)\n",
        "physics_data = iter(physics_dataset)\n",
        "\n",
        "\n",
        "pbar = trange(max_epochs)\n",
        "for epoch in pbar:\n",
        "\n",
        "    operator_batch = next(operator_data)\n",
        "    physics_batch = next(physics_data)\n",
        "\n",
        "    inputs_o, outputs_o = operator_batch\n",
        "    u_o, y_o = inputs_o\n",
        "    u_o, y_o, outputs_o = onp.array(u_o), onp.array(y_o), onp.array(outputs_o)\n",
        "    print(\"epoch: \", epoch)\n",
        "    print(\"size of operator inputs:\", len(u_o), len(y_o))\n",
        "    print(\"type of operator inputs:\", type(u_o), type(y_o))\n",
        "\n",
        "    inputs_p, outputs_p = operator_batch\n",
        "    u_p, y_p = inputs_p\n",
        "\n",
        "    print(\"size of physics inputs:\", len(u_p), len(y_p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "jBTIydXHGblz",
        "outputId": "4cf3fabf-21d2-4cc9-d469-ee0c6fb3e1f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [00:01<03:46,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n",
            "size of operator inputs: 10000 10000\n",
            "type of operator inputs: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "size of physics inputs: 10000 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/200 [00:02<03:51,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1\n",
            "size of operator inputs: 10000 10000\n",
            "type of operator inputs: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "size of physics inputs: 10000 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/200 [00:03<03:44,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  2\n",
            "size of operator inputs: 10000 10000\n",
            "type of operator inputs: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "size of physics inputs: 10000 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 4/200 [00:04<03:41,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  3\n",
            "size of operator inputs: 10000 10000\n",
            "type of operator inputs: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "size of physics inputs: 10000 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 5/200 [00:05<03:39,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  4\n",
            "size of operator inputs: 10000 10000\n",
            "type of operator inputs: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "size of physics inputs: 10000 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 6/200 [00:06<03:37,  1.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  5\n",
            "size of operator inputs: 10000 10000\n",
            "type of operator inputs: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "size of physics inputs: 10000 10000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 6/200 [00:07<04:15,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f4907c190066>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moperator_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mphysics_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysics_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minputs_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-04816383a5ff>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m'Generate one batch of data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the DeepOnet"
      ],
      "metadata": {
        "id": "EbUvcOjRIudt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Vanilla PyTorch model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, layers, activation=F.relu):\n",
        "        super(MLP, self).__init__()\n",
        "        self.activation = activation\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(layers)-1):\n",
        "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = self.activation(layer(x))\n",
        "        x = self.layers[-1](x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "tEC_UDe38JIm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DeepOnet class\n",
        "class DeepONet(nn.Module):\n",
        "    def __init__(self, branch_layers, trunk_layers):\n",
        "        super(DeepONet, self).__init__()\n",
        "\n",
        "        self.branch = MLP(branch_layers, torch.tanh)\n",
        "        self.trunk = MLP(trunk_layers, torch.tanh)\n",
        "\n",
        "    def forward(self, u, y):\n",
        "        B = self.branch(u)\n",
        "        T = self.trunk(y)\n",
        "        #print(\"B\", B)\n",
        "        outputs = torch.sum(B * T, dim=-1)                                   #WHY IS dim = -1 here?\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "MPZka2GC8QBL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title evaluation and derrivatives\n",
        "def s(model: nn.Module(), u: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Compute the value of the approximate solution from the DeepONet model\"\"\"\n",
        "    return model(u, y)\n",
        "\n",
        "\n",
        "def ds(model: nn.Module(), u: torch.Tensor, y: torch.Tensor, order: int = 1) -> torch.Tensor:\n",
        "    \"\"\"Compute neural network derivative with respect to input features using PyTorch autograd engine\"\"\"\n",
        "\n",
        "    df_value = s(model, u, y)\n",
        "\n",
        "\n",
        "    for _ in range(order):\n",
        "        df_value = torch.autograd.grad(\n",
        "            df_value.reshape((-1, 1)),\n",
        "            y,\n",
        "            grad_outputs=torch.ones_like(y),\n",
        "            create_graph=True,\n",
        "            retain_graph=True,\n",
        "        )[0]\n",
        "\n",
        "    return df_value\n"
      ],
      "metadata": {
        "id": "tNssBTyi8V0_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining loss functions that we want to minimize"
      ],
      "metadata": {
        "id": "Wj3NWxLuJHY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def residue(model:nn.Module(), u, y):\n",
        "\n",
        "    #TODO: adapt it to higer order derrivatives. Maybe we need to create a resideue class and define df inside it.\n",
        "\n",
        "    return ds(model,u, y)\n",
        "\n",
        "\n",
        "# Define operator loss\n",
        "def loss_operator(model:nn.Module, batch):\n",
        "    inputs, outputs = batch\n",
        "    u, y = inputs\n",
        "\n",
        "    #converting everything to numpy and then to torch tensor\n",
        "    u, y, outputs = onp.array(u), onp.array(y), onp.array(outputs)\n",
        "    u = torch.tensor(u, requires_grad=True)\n",
        "    y = torch.tensor(y, requires_grad=True)\n",
        "    outputs = torch.tensor(outputs, requires_grad=True)\n",
        "\n",
        "\n",
        "    pred = s(model, u, y)\n",
        "    #printing the size of each array as I realised that I was getting empty arrays with larger batch sizes.\n",
        "    ''' print(\"size of pred:\", len(pred))\n",
        "    print(\"size of u:\", len(u))\n",
        "    print(\"size of y:\", len(y)) '''\n",
        "\n",
        "\n",
        "    #pred = self(u, y)                                                  #STUPID LINE BY CHAT GPT\n",
        "    loss = torch.mean((outputs.view(-1) - pred.view(-1))**2)\n",
        "    return loss\n",
        "\n",
        "def loss_physics(model:nn.Module(), batch):\n",
        "\n",
        "    #TODO: clear the air regarding this loss. I think the formulation in the original code is wrong.\n",
        "\n",
        "    inputs, outputs = batch\n",
        "    u, y = inputs\n",
        "\n",
        "    #converting everything to numpy and then to torch tensors\n",
        "    u, y, outputs = onp.array(u), onp.array(y), onp.array(outputs)\n",
        "    u = torch.tensor(u, requires_grad=True)\n",
        "    y = torch.tensor(y, requires_grad=True)\n",
        "    outputs = torch.tensor(outputs, requires_grad=True)\n",
        "\n",
        "    pred = residue(model, u, y)\n",
        "\n",
        "\n",
        "    loss = torch.mean((outputs.view(-1) - pred.view(-1))**2)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "def total_loss(model:nn.Module(), operator_batch, physics_batch):\n",
        "    \"\"\"Summing up the two losses\"\"\"\n",
        "    #TODO: One can think of weighed sum of the two losses instead of plain sum.\n",
        "    loss_op = loss_operator(model, operator_batch)\n",
        "    loss_ph = loss_physics(model, physics_batch)\n",
        "\n",
        "    return loss_op + loss_ph\n"
      ],
      "metadata": {
        "id": "gBGAN-mt8Z5Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally we can train the model."
      ],
      "metadata": {
        "id": "aZ6sfcILJUDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model:nn.Module(),\n",
        "    operator_dataset,\n",
        "    physics_dataset,\n",
        "#    loss_fn: Callable,  #TODO: Make this callable like PINN script\n",
        "    initial_learning_rate:\n",
        "    int = 0.01,\n",
        "    max_epochs: int = 40000,\n",
        ")-> nn.Module():\n",
        "\n",
        "    #TODO: Put the following two parameters in arguments.\n",
        "    decay_steps = 1000\n",
        "    decay_rate = 0.9\n",
        "\n",
        "\n",
        "    operator_data = iter(operator_dataset)\n",
        "    physics_data = iter(physics_dataset)\n",
        "\n",
        "    pbar = trange(max_epochs)\n",
        "    for epoch in pbar:\n",
        "\n",
        "        operator_batch = next(operator_data)\n",
        "        physics_batch = next(physics_data)\n",
        "\n",
        "        '''         inputs_o, outputs_o = operator_batch\n",
        "        u_o, y_o = inputs_o\n",
        "        u_o, y_o, outputs_o = onp.array(u_o), onp.array(y_o), onp.array(outputs_o)\n",
        "        #print(\"epoch: \", epoch)\n",
        "        print(\"size of operator inputs:\", len(u_o), len(y_o))\n",
        "        print(\"type of operator inputs:\", type(u_o), type(y_o))\n",
        "        '''\n",
        "        # decaying learning rate\n",
        "        #learning_rate = initial_learning_rate * (decay_rate**(epoch/decay_steps))\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=initial_learning_rate)\n",
        "\n",
        "        #Optimization step\n",
        "        loss: torch.Tensor = total_loss(model, operator_batch, physics_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "\n",
        "            #compute losses\n",
        "            loss_value = total_loss(model, operator_batch, physics_batch)\n",
        "            loss_operator_value = loss_operator(model, operator_batch)\n",
        "            loss_physics_value = loss_physics(model, physics_batch)\n",
        "\n",
        "            print(f\"Epoch: {epoch} - Loss: {float(loss_value):>7f}\",\n",
        "                    f\"Loss Physics: {float(loss_physics_value):>7f}\"\n",
        "                        f\"Loss Operator: {float(loss_operator_value):>7f}\")\n",
        "\n",
        "\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-xhjdzTr8fXD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the object PI_DeepOneta\n",
        "m = 100\n",
        "branch_layers = [m, 50, 50, 50, 50, 50]\n",
        "trunk_layers =  [1, 50, 50, 50, 50, 50]\n",
        "model = DeepONet(branch_layers, trunk_layers)"
      ],
      "metadata": {
        "id": "bdjWUZ9X8jB1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LET US TRAIN THE NETWORK NOW\n",
        "#loss_fn = partial(total_loss, ) #TODO: complete this to make loss_fn callable\n",
        "trained_model = train(model, operator_dataset, physics_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "yejH6kkg8oAW",
        "outputId": "9a14147c-a415-4270-93ad-2bf1a19c1ad2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/40000 [00:02<23:10:05,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 - Loss: 1.244428 Loss Physics: 0.987765Loss Operator: 0.256663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 51/40000 [01:09<15:19:53,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50 - Loss: 1.146872 Loss Physics: 0.971613Loss Operator: 0.175259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 101/40000 [02:18<14:25:49,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 100 - Loss: 1.015501 Loss Physics: 0.845070Loss Operator: 0.170431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 151/40000 [03:26<15:36:23,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 150 - Loss: 1.288554 Loss Physics: 1.168812Loss Operator: 0.119742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 201/40000 [04:36<17:44:44,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 200 - Loss: 0.921753 Loss Physics: 0.743011Loss Operator: 0.178742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 251/40000 [05:44<15:44:48,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 250 - Loss: 0.876132 Loss Physics: 0.722714Loss Operator: 0.153418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 301/40000 [06:52<14:24:33,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 300 - Loss: 0.725970 Loss Physics: 0.619660Loss Operator: 0.106310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 351/40000 [08:00<16:14:55,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 350 - Loss: 0.561937 Loss Physics: 0.494897Loss Operator: 0.067040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 401/40000 [09:08<14:49:35,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 400 - Loss: 0.694941 Loss Physics: 0.577832Loss Operator: 0.117109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 451/40000 [10:18<17:24:15,  1.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 450 - Loss: 0.559140 Loss Physics: 0.471276Loss Operator: 0.087864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 501/40000 [11:26<14:42:52,  1.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 500 - Loss: 0.580570 Loss Physics: 0.494653Loss Operator: 0.085917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 551/40000 [12:36<16:19:58,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 550 - Loss: 0.562382 Loss Physics: 0.485354Loss Operator: 0.077029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 601/40000 [13:45<15:06:37,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 600 - Loss: 0.439897 Loss Physics: 0.376824Loss Operator: 0.063072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 651/40000 [14:55<15:51:38,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 650 - Loss: 0.469134 Loss Physics: 0.414000Loss Operator: 0.055134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 701/40000 [16:03<14:52:44,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 700 - Loss: 0.500611 Loss Physics: 0.431242Loss Operator: 0.069369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 751/40000 [17:13<16:04:15,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 750 - Loss: 0.307711 Loss Physics: 0.279774Loss Operator: 0.027936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 801/40000 [18:20<14:44:54,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 800 - Loss: 0.430131 Loss Physics: 0.375812Loss Operator: 0.054319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 851/40000 [19:29<15:51:16,  1.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 850 - Loss: 0.467090 Loss Physics: 0.403372Loss Operator: 0.063719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 901/40000 [20:37<14:38:44,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 900 - Loss: 0.619500 Loss Physics: 0.470818Loss Operator: 0.148681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 951/40000 [21:46<17:02:01,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 950 - Loss: 0.407128 Loss Physics: 0.356406Loss Operator: 0.050722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1001/40000 [22:52<14:46:15,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1000 - Loss: 0.350971 Loss Physics: 0.297015Loss Operator: 0.053956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1051/40000 [24:00<14:37:36,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1050 - Loss: 0.375065 Loss Physics: 0.335332Loss Operator: 0.039733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1101/40000 [25:08<15:36:29,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1100 - Loss: 0.461095 Loss Physics: 0.386516Loss Operator: 0.074579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1151/40000 [26:20<16:27:00,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1150 - Loss: 0.385907 Loss Physics: 0.307212Loss Operator: 0.078695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1201/40000 [27:30<15:37:21,  1.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1200 - Loss: 0.386439 Loss Physics: 0.327964Loss Operator: 0.058475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1251/40000 [28:39<19:32:46,  1.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1250 - Loss: 0.355715 Loss Physics: 0.267412Loss Operator: 0.088304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 1297/40000 [29:42<14:46:20,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-c1bbc482173a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#LET US TRAIN THE NETWORK NOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#loss_fn = partial(total_loss, ) #TODO: complete this to make loss_fn callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphysics_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-e7ebbaaa1216>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, operator_dataset, physics_dataset, initial_learning_rate, max_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moperator_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mphysics_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysics_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         '''         inputs_o, outputs_o = operator_batch\n",
            "\u001b[0;32m<ipython-input-6-04816383a5ff>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m'Generate one batch of data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H3AH6h1sBA3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqKVtI2VBEfv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}